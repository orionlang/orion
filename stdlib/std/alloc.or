// Allocator interface
// All allocators must implement this class

class Allocator {
  alloc: fn(Self, U64) ptr;
  free: fn(Self, ptr) ();
  realloc: fn(Self, ptr, U64) Bool;
  remap: fn(Self, ptr, U64) ptr;
}

// System calls for memory management
extern "C" {
  fn mmap(addr: ptr, length: U64, prot: I32, flags: I32, fd: I32, offset: I64) ptr;
  fn munmap(addr: ptr, length: U64) I32;
}

// mmap constants
// PROT flags
// var PROT_READ: I32 = 1
// var PROT_WRITE: I32 = 2
// MAP flags
// var MAP_PRIVATE: I32 = 2
// var MAP_ANONYMOUS: I32 = 32

// Page allocator - allocates memory in page-sized chunks using mmap
// Each allocation is independent and can be freed with munmap
type PageAllocator = {
  page_size: U64,  // Standard page size (4096)
}

instance Allocator[PageAllocator] {
  alloc = fn(self: PageAllocator, num_pages: U64) ptr {
    unsafe {
      var pa: PageAllocator = self

      // Calculate total size to allocate
      var total_size: U64 = num_pages * pa.page_size

      // mmap(NULL, length, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0)
      // Use @int_to_ptr to create NULL pointer
      var null_addr: U64 = 0
      var addr: ptr = @int_to_ptr(null_addr)
      var prot: I32 = 3  // PROT_READ | PROT_WRITE
      var flags: I32 = 34  // MAP_PRIVATE | MAP_ANONYMOUS
      var fd: I32 = -1
      var offset: I64 = 0

      var ptr: ptr = mmap(addr, total_size, prot, flags, fd, offset)
      return ptr
    }
  }

  free = fn(self: PageAllocator, ptr: ptr, num_pages: U64) () {
    unsafe {
      var pa: PageAllocator = self
      var total_size: U64 = num_pages * pa.page_size
      var result: I32 = munmap(ptr, total_size)
      return ()
    }
  }

  realloc = fn(self: PageAllocator, ptr: ptr, new_size: U64) Bool {
    // PageAllocator doesn't support in-place realloc
    return false
  }

  remap = fn(self: PageAllocator, ptr: ptr, old_pages: U64, new_pages: U64) ptr {
    unsafe {
      var pa: PageAllocator = self
      // Allocate new mapping
      var new_ptr: ptr = pa.alloc(new_pages)
      // TODO: copy old data to new_ptr (need memcpy)
      // Free old mapping
      pa.free(ptr, old_pages)
      return new_ptr
    }
  }
}

// Arena allocator - bump allocator, all freed at once
// Uses a PageAllocator as backing allocator
type Arena = {
  parent: PageAllocator,  // Backing allocator
  buffer: ptr,
  capacity: U64,
  used: U64,
}

instance Allocator[Arena] {
  alloc = fn(self: Arena, size: U64) (ptr, Arena) {
    unsafe {
      var arena: Arena = self

      // Check if we need to grow the arena
      var new_used: U64 = arena.used + size
      var needs_grow: Bool = new_used > arena.capacity

      var arena_updated: Arena = if needs_grow {
        // Allocate more pages from parent
        // Calculate how many pages we need
        var page_size: U64 = arena.parent.page_size
        var bytes_needed: U64 = new_used - arena.capacity
        var pages_needed: U64 = (bytes_needed + page_size - 1) / page_size  // Round up

        // Allocate from parent
        var new_buffer: ptr = arena.parent.alloc(pages_needed)
        var new_capacity: U64 = arena.capacity + (pages_needed * page_size)

        // For simplicity, just use new buffer (TODO: copy old data)
        Arena {
          parent: arena.parent,
          buffer: new_buffer,
          capacity: new_capacity,
          used: 0,
        }
      } else {
        arena
      }

      // Allocate from arena
      var alloc_ptr: ptr = @ptr_offset(arena_updated.buffer, arena_updated.used)

      // Return updated arena with incremented used counter
      var final_arena: Arena = Arena {
        parent: arena_updated.parent,
        buffer: arena_updated.buffer,
        capacity: arena_updated.capacity,
        used: new_used,
      }

      return (alloc_ptr, final_arena)
    }
  }

  free = fn(self: Arena, ptr: ptr) () {
    // Arena doesn't free individual allocations
    return ()
  }

  realloc = fn(self: Arena, ptr: ptr, new_size: U64) Bool {
    // Arena doesn't support in-place realloc
    return false
  }

  remap = fn(self: Arena, old_ptr: ptr, new_size: U64) ptr {
    // Arena can't remap
    unsafe {
      var arena: Arena = self
      return arena.buffer
    }
  }
}

// General purpose allocator - maintains free list
// Uses first-fit allocation strategy with simple free list
// Block layout: [size: U64][next: ptr][user data...]
type FreeBlock = {
  size: U64,
  next: ptr,
}

type GeneralPurposeAllocator = {
  parent: PageAllocator,  // Backing page allocator
  free_list: ptr,   // Head of free list (null if empty)
  heap_start: ptr,  // Start of heap
  heap_end: ptr,    // Current end of heap
}

instance Allocator[GeneralPurposeAllocator] {
  alloc = fn(self: GeneralPurposeAllocator, size: U64) (ptr, GeneralPurposeAllocator) {
    unsafe {
      var gpa: GeneralPurposeAllocator = self
      var header_size: U64 = 16  // Size of FreeBlock header
      var total_size: U64 = size + header_size

      // Search free list for first-fit block
      var null_addr: U64 = 0
      var null_ptr: ptr = @int_to_ptr(null_addr)
      var current: ptr = gpa.free_list
      var prev: ptr = null_ptr

      // Walk free list looking for a block large enough
      var found_block: ptr = null_ptr
      var found_prev: ptr = null_ptr

      var searching: Bool = current != null_ptr
      var continue_search: Bool = searching

      // Simple linear search through free list
      var search_result: (ptr, ptr, Bool) = if searching {
        // Read first block
        var block_size: U64 = @ptr_read(current, @type(U64))
        var fits: Bool = block_size >= total_size

        if fits {
          (current, null_ptr, false)  // found, prev, continue
        } else {
          var next_offset1: ptr = @ptr_offset(current, 8)
          var next: ptr = @ptr_read(next_offset1, @type(ptr))
          (next, current, next != null_ptr)
        }
      } else {
        (null_ptr, null_ptr, false)
      }

      found_block = search_result.0
      found_prev = search_result.1
      continue_search = search_result.2

      // Continue searching if needed (simplified - only checks one more block)
      var final_result: (ptr, ptr) = if continue_search {
        var curr: ptr = found_block
        var pr: ptr = found_prev

        var block_size2: U64 = @ptr_read(curr, @type(U64))
        var fits2: Bool = block_size2 >= total_size

        if fits2 {
          (curr, pr)
        } else {
          (null_ptr, null_ptr)
        }
      } else {
        (found_block, found_prev)
      }

      found_block = final_result.0
      found_prev = final_result.1

      // If found a free block, use it
      var allocated_ptr: ptr = if found_block != null_ptr {
        // Remove from free list
        var next_offset2: ptr = @ptr_offset(found_block, 8)
        var next_block: ptr = @ptr_read(next_offset2, @type(ptr))

        var new_free_list: ptr = if found_prev == null_ptr {
          // Removing head of list
          next_block
        } else {
          // Removing from middle
          var prev_next_offset: ptr = @ptr_offset(found_prev, 8)
          var _w3: () = @ptr_write(prev_next_offset, next_block)
          gpa.free_list
        }

        var updated_gpa: GeneralPurposeAllocator = GeneralPurposeAllocator {
          parent: gpa.parent,
          free_list: new_free_list,
          heap_start: gpa.heap_start,
          heap_end: gpa.heap_end,
        }
        gpa = updated_gpa

        @ptr_offset(found_block, header_size)
      } else {
        // No free block found, allocate from parent
        // Calculate how many pages we need
        var page_size: U64 = gpa.parent.page_size
        var pages_needed: U64 = (total_size + page_size - 1) / page_size  // Round up

        var new_block: ptr = gpa.parent.alloc(pages_needed)

        // Write block header
        var _w1: () = @ptr_write(new_block, total_size)
        var next_offset: ptr = @ptr_offset(new_block, 8)
        var _w2: () = @ptr_write(next_offset, null_ptr)

        @ptr_offset(new_block, header_size)
      }

      var final_gpa: GeneralPurposeAllocator = gpa
      return (allocated_ptr, final_gpa)
    }
  }

  free = fn(self: GeneralPurposeAllocator, ptr: ptr) GeneralPurposeAllocator {
    unsafe {
      var gpa: GeneralPurposeAllocator = self
      var header_size: U64 = 16

      // Get block header by going backwards from user pointer
      // Convert ptr to int, subtract header size, convert back to ptr
      var ptr_as_int: U64 = @ptr_to_int(ptr)
      var header_size_as_int: U64 = 16
      var block_start_int: U64 = ptr_as_int - header_size_as_int
      var block_start: ptr = @int_to_ptr(block_start_int)

      // Read current free list head
      var old_head: ptr = gpa.free_list

      // Write old head as next pointer for this block
      var next_offset: ptr = @ptr_offset(block_start, 8)
      var _w1: () = @ptr_write(next_offset, old_head)

      // Return updated GPA with this block as new head
      return GeneralPurposeAllocator {
        parent: gpa.parent,
        free_list: block_start,
        heap_start: gpa.heap_start,
        heap_end: gpa.heap_end,
      }
    }
  }

  realloc = fn(self: GeneralPurposeAllocator, ptr: ptr, new_size: U64) Bool {
    // Try to expand in-place
    // For bootstrap, always return false (not supported yet)
    return false
  }

  remap = fn(self: GeneralPurposeAllocator, ptr: ptr, new_size: U64) (ptr, GeneralPurposeAllocator) {
    unsafe {
      var gpa: GeneralPurposeAllocator = self

      // Allocate new block
      var alloc_result: (ptr, GeneralPurposeAllocator) = gpa.alloc(new_size)
      var new_ptr: ptr = alloc_result.0
      var gpa2: GeneralPurposeAllocator = alloc_result.1

      // Copy old data to new location
      // TODO: Need memcpy or manual copy loop
      // For now, just return new pointer without copying

      // Free old block
      var gpa3: GeneralPurposeAllocator = gpa2.free(ptr)

      return (new_ptr, gpa3)
    }
  }
}

// Helper functions for Arena

// Create a new arena
// parent_alloc: PageAllocator to use for backing memory
// Arena starts with zero capacity and grows on demand
fn arena_create(parent_alloc: PageAllocator) Arena {
  // Start with no buffer, will allocate on first alloc
  var null_addr: U64 = 0
  var null_ptr: ptr = unsafe { @int_to_ptr(null_addr) }

  return Arena {
    parent: parent_alloc,
    buffer: null_ptr,
    capacity: 0,
    used: 0,
  }
}

// Reset arena (free all allocations, reset used counter)
fn arena_reset(arena: Arena@3) Arena {
  return Arena {
    parent: arena.parent,
    buffer: arena.buffer,
    capacity: arena.capacity,
    used: 0,
  }
}

// Destroy arena (currently no-op, memory stays allocated)
fn arena_destroy(arena: Arena@?) () {
  // TODO: Could use brk to shrink heap back
  return ()
}

// Helper functions for allocator creation

fn page_allocator_create() PageAllocator {
  // Standard page size is 4096 bytes (4KB)
  return PageAllocator {
    page_size: 4096,
  }
}

fn gpa_create(parent_alloc: PageAllocator) GeneralPurposeAllocator {
  var null_addr: U64 = 0
  var null_ptr: ptr = unsafe { @int_to_ptr(null_addr) }

  return GeneralPurposeAllocator {
    parent: parent_alloc,
    free_list: null_ptr,
    heap_start: null_ptr,
    heap_end: null_ptr,
  }
}
